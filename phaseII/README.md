# Phase II: Refining interaction and designing wireframes

## Introduction

In Phase II, our team focused on refining the interaction design of our heart disease risk predictor and creating detailed wireframes based on feedback from Phase I. Previously, we identified questions such as whether to use a trained machine learning model or a mathematical equation, if user profiles should be included, and whether we should offer resources for heart disease prevention. This phase aimed to resolve these issues and improve the user interface, data collection, and presentation.

## Methods

For this phase, we used two main research methods: cognitive walkthroughs and informal feedback.

In the cognitive walkthrough, three UX evaluators individually tested the website. Each evaluator represented a persona that we previously defined. These personas included different demographics and health contexts. The evaluators followed detailed steps provided by Chapter 4 guidelines on cognitive walkthroughs from the assigned text. At each step, evaluators answered specific questions to determine if the interface was clear and usable. They evaluated aspects such as whether users could understand the purpose of the page, if they knew how to proceed to the next step, and if they could complete tasks without confusion.

We also gathered informal feedback from approximately 35 undergraduate software engineering students. During a presentation, our software engineering team asked the class: 

> What factors would make you trust an AI model to assess your risks? Would transparency about its training data, accuracy, and methodology be enough, or would you need additional assurances?

## Findings

During the cognitive walkthrough, evaluators generally found the website easy to use and clear. However, one evaluator pointed out specific issues related to entering biometric data. They found the instructions unclear, specifically about what certain biometric data meant and how to obtain them. The evaluator recommended providing clearer explanations and more detailed instructions on acquiring biometric data.

Informal feedback from the undergraduate class revealed that transparency was the most critical factor for trusting the AI model. They emphasized that clear explanations about the modelâ€™s training data, its accuracy, and how it calculates risk would significantly increase trust.

## Conclusions

Based on our findings, we concluded that we needed to revise the user interface to make entering biometric data more intuitive. We decided to add clear explanations and simple instructions, especially for biometric inputs that users might find difficult to understand or obtain.

We also decided to include more transparent explanations about how the model works. Specifically, we planned to provide straightforward information about the training data used, the accuracy of predictions, and the methodology behind risk calculations. These changes were reflected in our updated wireframes, user stories, and scenarios to ensure users feel more confident and comfortable using the tool.

## Caveats

One limitation of our approach was the reliance on secondary research and a small user sample. This limitation means our results might not represent all user experiences or interactions accurately. To address this limitation, future research should include more extensive user testing with diverse demographics.

Additionally, cognitive walkthroughs, while helpful, may not fully capture all real-world usability issues. Future phases should conduct detailed interviews and real-world usability testing to gain more comprehensive insights into how users interact with our tool in various contexts.

