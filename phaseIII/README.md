# Phase III: Prototypes and User Testing

## Introduction

In Phase III, our team focused on conducting user studies based on our wireframe prototypes, which were modified based on feedback from the previous two phases. This phase aimed to assess how the wireframe performed with individuals unfamiliar with our user study, and to gather data for further improving the wireframe.

## Methods

For this study, we used a user study, looking at how people used our wireframe prototype (which you can find linked on the home page). The user study had both questions at the beginning and tasks for people to do, and we had them think aloud, to see how they experienced the app. We also had the partcipants use the think-aloud protocol, where participants verbalized their thoughts and actions while navigating the site. This method allowed us to gain insights into their decision-making processes, navigation, and perceptions of the interface, helped us write detailed notes.

**Preliminary Questions:**

We started by asking people about their past experience with health apps and what they expected from an app that checks heart health risk:
  
  > Have you ever used a health or medical application or website before?
  
  > What was your experience like, and what features did you find helpful or frustrating?
  
  > What do you expect when using an app designed to check your heart health risk?

Then, we gave people four tasks to do using the wireframe prototype. We wrote down how they moved through the app and what they said as they were thinking aloud.

**Task 1: Check Risk Without an Account**

Participants were instructed to imagine a friend recommending the site for checking heart risk percentage without needing an account. We observed how they located and used the risk assessment form.

After they finished, we asked:

  > Able to navigate the site, enter biometrics, and get your risks: ⃞ Yes ⃞ No
  
  > On a scale from 1 to 5, where 1 is "Very Difficult" and 5 is "Very Easy", how would you rate completing this task on this prototype? Why?

These questions aimed to gather quantitative data on task completion and perceived difficulty, along with qualitative data explaining their ease-of-use rating.

**Task 2: Check Risk With an Account**

Participants were required to create an account and then enter their biometrics to obtain their risk assessment. This task assessed the account creation process and subsequent navigation.

After they finished, we asked:

  > Able to create an account, enter biometrics, and get your risks: ⃞ Yes ⃞ No
  
  > On a scale from 1 to 5, where 1 is "Very Difficult" and 5 is "Very Easy", how would you rate completing this task on this prototype? Why?

These questions gave us numbers on whether they could do the task and how hard it was, and words on why they rated it that way.

**Task 3: Understanding the AI Model and Results**

People were told to go to the 'About' page to learn about the model, then enter their information, submit it, and look at their results. This task checked if people understood the model, trusted the information, and found the results easy to understand.

After they finished, we asked:

  > Able to understand the AI model from the ‘About Page’, enter biometrics, and understand the dashboard: ⃞ Yes ⃞ No
  
  > On a scale from 1 to 5, where 1 is "Very Difficult" and 5 is "Very Easy", how would you rate completing this task on this prototype? Why?
  
  > Did the information on the page make you trust the AI model more?
  
  > Was the results page clear and easy to understand? What did you find confusing?

These questions assessed task completion, perceived difficulty, trust in the AI model, and clarity/usability of the dashboard.

**Task 4: Looking at Extra Resources**

Participants were instructed to navigate the site and explore available help pages and resources. This task aimed to evaluate the discoverability and usefulness of these resources.

After they finished, we asked:

  > Able to successfully identify and explore additional resources or features beyond basic risk assessment: ⃞ Yes ⃞ No
  
  > On a scale from 1 to 5, where 1 is "Very Difficult" and 5 is "Very Easy", how would you rate completing this task on this prototype? Why?
  
  > Did you find these resources helpful or relevant to your health concerns?

These questions assessed task completion, perceived difficulty, and the helpfulness/relevance of the resources.

## Findings

- [In findings] A summary of your data (including overall trends in qualitative and quantitative data
- [In findings] A link to the spreadsheet for data collection, with rows filled out representing the data collected

## Conclusions

!!! Discoveries derived from the methods and their findings. Interpret how the findings translate into new insights into UX design recommendations. Describe those recommendations and how they should shape future work. In this section, include the new design recommendations based on the latest user insights. !!!

- [In conclusions] The interpretation of your findings, including both (A) recommended changes to improve the user experience and (B) aspects of the design that are affirmed to remain as-is

## Caveats

Our study has several limitations that should be considered when interpreting the findings. First, our participant pool primarily consisted of Computer Science students, and many participants were known to the researchers. This introduces potential biases, as their familiarity with technology and the research team could influence their interactions with the prototype and their feedback. Second, the sample was predominantly male, which limits the generalizability of our results to a broader population. Finally, our study may not have uncovered all potential usability issues or user preferences due to the specific tasks and questions we employed.
